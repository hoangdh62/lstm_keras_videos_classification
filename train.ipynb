{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMCzuGccy4e/E3i35gzytbZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JMKdFY_LCWsi","colab_type":"code","colab":{}},"source":["!apt-get update -qq 2>&1 > /dev/null\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!pip install keras==2.1.6\n","!pip install tensorflow-gpu==1.13.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_m6191w1ELuI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592532159290,"user_tz":-420,"elapsed":1691,"user":{"displayName":"Mạnh Đỗ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimGlmHD1VpWlhJkxICi86KqJqyhBpGFDbjj7se=s64","userId":"08283046787953229489"}},"outputId":"edcb229d-a85e-4bbf-95e3-37f9da0aaa6f"},"source":["cd gdrive/My Drive/HoangDH/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/HoangDH\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g9N9JpP4FGwb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"6349e7b2-21d6-4228-cd07-c3c1aa420d56"},"source":["from keras.layers import Conv2D, GlobalAveragePooling2D, Dense, LSTM, BatchNormalization, Flatten, Dropout, TimeDistributed, Lambda, Input\n","from keras.models import Model, Sequential\n","from keras.applications.resnet50 import ResNet50\n","from keras.optimizers import Adam\n","import keras.backend as K\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras.metrics import categorical_accuracy\n","import os\n","import cv2\n","import numpy as np\n","from random import randint\n","from PIL import Image\n","from tqdm import tqdm\n","\n","\n","def create_model(categories, batch_size, frames, channels, pixels_x, pixels_y):\n","    input = Input(shape=(frames, pixels_x, pixels_y, channels))\n","    input_resnet = Lambda(lambda x: K.reshape(input, shape=(batch_size*frames, pixels_x, pixels_y, channels)))(input)\n","    out_resnet = ResNet50(\n","        include_top=False,\n","        weights='imagenet',\n","        input_shape=(pixels_x, pixels_y, 3),\n","        pooling='max'\n","    )(input_resnet)\n","    # out_resnet = K.reshape(out_resnet, shape=(batch_size, frames, -1))\n","    out_resnet = Lambda(lambda x: K.reshape(out_resnet, shape=(batch_size, frames, -1)))(out_resnet)\n","    out_lstm = LSTM(256, activation='relu', return_sequences=False)(out_resnet)\n","    middle_dense = Dense(128, activation='relu')(out_lstm)\n","    # middle_dense = Dropout(0.5)(middle_dense)\n","    out = Dense(len(categories), activation='softmax')(middle_dense)\n","\n","    model = Model(input, out)\n","    return model\n","\n","\n","def generator(root, batch_size, num_frames, width, height, channels, is_train=True, return_image=False):\n","    max_frames = 4*num_frames\n","    categories = os.listdir(root)\n","    cat_map = {}\n","    for i, cat in enumerate(categories):\n","        cat_map[cat] = i\n","\n","    if is_train:\n","        with open('trainlist01.txt', 'r') as file:\n","            lines = file.readlines()\n","            data_paths = [(root + path.split()[0].strip(), path.split('/')[0]) for path in lines]\n","    else:\n","        with open('testlist01.txt', 'r') as file:\n","            lines = file.readlines()\n","            data_paths = [(root + path.split()[0].strip(), path.split('/')[0]) for path in lines]\n","\n","    while True:\n","        batch_xdata = np.zeros(shape=(batch_size, num_frames, width, height, channels))\n","        batch_ydata = np.zeros(shape=(batch_size, len(categories)))\n","        videos = []\n","        # chọn ngẫu nhiên 'batch_size' videos từ kho\n","        video_indexs = np.random.choice(list(range(len(data_paths))), size=batch_size)\n","        for idx, video_index in enumerate(video_indexs):\n","            video_path, cat = data_paths[video_index]\n","            cat_id = cat_map[cat]\n","            data = []\n","            frames = []\n","            cap = cv2.VideoCapture(video_path)\n","            while(cap.isOpened()):\n","                ret, frame = cap.read()\n","                if not ret:\n","                    break\n","                # augment data\n","                if randint(0, 1):\n","                     frame = cv2.flip(frame, 1)\n","\n","                frames.append(frame)\n","                # frame = frame/128 - 1\n","                # resize image to width, height\n","                w, h = frame.shape[:-1]\n","                scale = min(width/w, height/h)\n","                nw = int(scale*w)\n","                nh = int(scale*h)\n","                frame = cv2.resize(frame, (nh, nw))\n","                # paste image in zeros background\n","                frame_data = np.zeros(shape=(width, height, channels))\n","                frame_data[(width-nw)//2:(width-nw)//2+nw, (height-nh)//2:(height-nh)//2+nh, :] = frame\n","                # cv2.imshow('test', frame_data)\n","                data.append(frame_data)\n","            cap.release()\n","            # Cắt bớt frame ở đầu nếu số frame lơn hơn num_frames\n","            # Nếu thiếu thì padding trái\n","            if len(data) > max_frames:\n","                offset = randint(0, len(data) - max_frames)\n","                data = data[offset: offset+max_frames]\n","                frames = frames[offset: offset+max_frames]\n","            train_data = []\n","            for i, f in enumerate(data):\n","                if i%4 == 0:\n","                    train_data.append(data[i])\n","            data = train_data\n","            # paste it in batch_data\n","            offset = num_frames - len(data)\n","            batch_xdata[idx, offset:, :, :, :] = np.asarray(data)\n","            batch_ydata[idx, cat_id] = 1\n","            videos.append(frames)\n","        if return_image:\n","            yield videos, batch_xdata, batch_ydata\n","        else:\n","            yield batch_xdata, batch_ydata\n","\n","def process_video(video_path, width, height, channels):\n","    processed_frames = []\n","    frames = []\n","    cap = cv2.VideoCapture(video_path)\n","    while (cap.isOpened()):\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        w, h = frame.shape[:-1]\n","        scale = min(width / w, height / h)\n","        nw = int(scale * w)\n","        nh = int(scale * h)\n","        frame = cv2.resize(frame, (nh, nw))\n","        # paste image in zeros background\n","        frame_data = np.zeros(shape=(width, height, channels))\n","        frame_data[(width - nw) // 2:(width - nw) // 2 + nw, (height - nh) // 2:(height - nh) // 2 + nh, :] = frame\n","        processed_frames.append(frame_data)\n","        frames.append(frame)\n","    cap.release()\n","    return np.asarray(processed_frames), frames\n","\n","def predict_val(model, root, num_frames, width, height, channels):\n","    data_paths = []\n","    categories = os.listdir(root)\n","    cat_map = {}\n","    for cat_id, cat in enumerate(categories):\n","        cat_map[cat] = cat_id\n","        data_paths += ['{}{}/{}'.format(root, cat, video) for video in os.listdir(root + cat)][:4]\n","\n","    for data_path in tqdm(data_paths):\n","        video_name = data_path.split('/')[-1]\n","        data, frames = process_video(data_path, width, height, channels)\n","        batch_size = len(data)//(num_frames//2) - 1\n","\n","        fheight, fwidth = frames[0].shape[:-1]\n","        out = cv2.VideoWriter('output/' + video_name, cv2.VideoWriter_fourcc(*'XVID'), 24, (fwidth, fheight))\n","        for idx in range(batch_size):\n","            begin = (num_frames//2)*idx\n","            end = begin + num_frames\n","            X = np.expand_dims(data[begin:end, :], axis=0)\n","            y_pred = model.predict(X)\n","            cat_id = np.argmax(y_pred[0])\n","            cat_pre = categories[cat_id]\n","            confidence = y_pred[0][cat_id]\n","            for i in range(begin, end, 1):\n","                frames[i] = cv2.putText(frames[i], '{}:{}'.format(cat_pre, confidence), (0, 50), cv2.FONT_HERSHEY_SIMPLEX,\n","                                    0.5, (255, 0, 0), thickness=1, lineType=cv2.LINE_AA)\n","        for frame in frames:\n","            out.write(frame)\n","        out.release()\n","\n","if __name__ == '__main__':\n","    root_data = 'data/'\n","    log_dir = 'logs/'\n","    batch_size = 4\n","    num_frames = 6\n","    width = 224\n","    height = 224\n","    channels = 3\n","    # gen = generator(root_data, batch_size, num_frames, width, height, channels, True)\n","    # for data in gen:\n","    #     x = data\n","\n","    categories = os.listdir(root_data)\n","    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-acc{acc:.3f}-val_loss{val_loss:.3f}-val_acc{val_acc:.3f}.h5',\n","                                 monitor='val_loss', save_weights_only=True, save_best_only=False, period=1)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n","    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)\n","    model = create_model(categories, batch_size, num_frames, channels, width, height)\n","    model.compile(optimizer=Adam(lr=1e-5), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n","    # model.load_weights('logs/ep008-loss0.076-val_loss0.987.h5')\n","    history = model.fit_generator(generator(root_data, batch_size, num_frames, width, height, channels, True),\n","                        steps_per_epoch=200,\n","                        validation_data=generator(root_data, batch_size, num_frames, width, height, channels, False),\n","                        validation_steps=300,\n","                        epochs=10,\n","                        initial_epoch=0,\n","                        callbacks=[checkpoint, reduce_lr])\n","    with open('logs.txt', 'a') as file:\n","        file.writelines('batch: {}, num_frames: {}\\n'.format(batch_size, num_frames))\n","        file.writelines('loss: {}\\n'.format(history['loss'].join(' ')))\n","        file.writelines('acc: {}\\n'.format(history['acc'].join(' ')))\n","        file.writelines('val_loss: {}\\n'.format(history['val_loss'].join(' ')))\n","        file.writelines('val_acc: {}\\n'.format(history['val_acc'].join(' ')))\n","\n","    # results = model.evaluate_generator(generator(root_data, batch_size, num_frames, width, height, channels, False),\n","    #                                   steps=20, verbose=1)\n","    # print(results)\n","\n","    # gen = generator(root_data, batch_size, num_frames, width, height, channels, is_train=False, return_image=True)\n","    # count = 0\n","    # for i in tqdm(range(100)):\n","    #     videos, X, y = gen.__next__()\n","    #     y_preds = model.predict(X)\n","    #     for i in range(batch_size):\n","    #         frames = videos[i]\n","    #         category = categories[np.argmax(y_preds[i])]\n","    #         if np.argmax(y[i]) == np.argmax(y_preds[i]):\n","    #             count += 1\n","    # print(count)\n","    # predict_val(model, root_data, num_frames, width, height, channels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","200/200 [==============================] - 233s 1s/step - loss: 0.9875 - acc: 0.6962 - val_loss: 0.6650 - val_acc: 0.7483\n","Epoch 2/10\n","166/200 [=======================>......] - ETA: 14s - loss: 0.2631 - acc: 0.9413"],"name":"stdout"}]}]}